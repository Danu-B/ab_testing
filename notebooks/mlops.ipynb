{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn import tree\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data by browser and platform_os, and version each split as a new version of the data in dvc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008aafdf-deef-4482-8fec-d98e3da054da</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>16</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00b6fadb-10bd-49e3-a778-290da82f7a8d</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>4</td>\n",
       "      <td>Samsung SM-A202F</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018af862-486e-4da1-a85b-71872120e57c</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023ec7b5-cb8f-49a5-995f-e0d7c2f702e5</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>13</td>\n",
       "      <td>Samsung SM-G935F</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02efdb70-8596-4f3f-b0b2-b91e194f61f7</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>6</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id experiment        date  hour  \\\n",
       "0  008aafdf-deef-4482-8fec-d98e3da054da    exposed  2020-07-04    16   \n",
       "1  00b6fadb-10bd-49e3-a778-290da82f7a8d    control  2020-07-08     4   \n",
       "2  018af862-486e-4da1-a85b-71872120e57c    control  2020-07-03    15   \n",
       "3  023ec7b5-cb8f-49a5-995f-e0d7c2f702e5    exposed  2020-07-09    13   \n",
       "4  02efdb70-8596-4f3f-b0b2-b91e194f61f7    exposed  2020-07-05     6   \n",
       "\n",
       "          device_make  platform_os        browser  user_response  \n",
       "0  Generic Smartphone            6  Chrome Mobile              1  \n",
       "1    Samsung SM-A202F            6       Facebook              1  \n",
       "2  Generic Smartphone            6  Chrome Mobile              1  \n",
       "3    Samsung SM-G935F            6       Facebook              1  \n",
       "4  Generic Smartphone            6  Chrome Mobile              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = pd.read_csv('../data/data_with_response.csv')\n",
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# \n",
    "df_split['experiment'] = label_encoder.fit_transform(df_split['experiment'])\n",
    "df_split['date'] = label_encoder.fit_transform(df_split['date'])\n",
    "df_split['hour'] = label_encoder.fit_transform(df_split['hour'])\n",
    "df_split['device_make'] = label_encoder.fit_transform(df_split['device_make'])\n",
    "df_split['platform_os'] = label_encoder.fit_transform(df_split['platform_os'])\n",
    "df_split['browser'] = label_encoder.fit_transform(df_split['browser'])\n",
    "df_split['user_response'] = label_encoder.fit_transform(df_split['user_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Data With Browsers and Platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008aafdf-deef-4482-8fec-d98e3da054da</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00b6fadb-10bd-49e3-a778-290da82f7a8d</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018af862-486e-4da1-a85b-71872120e57c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023ec7b5-cb8f-49a5-995f-e0d7c2f702e5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02efdb70-8596-4f3f-b0b2-b91e194f61f7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id  experiment  date  hour  device_make  \\\n",
       "0  008aafdf-deef-4482-8fec-d98e3da054da           1     1    16           13   \n",
       "1  00b6fadb-10bd-49e3-a778-290da82f7a8d           0     5     4           43   \n",
       "2  018af862-486e-4da1-a85b-71872120e57c           0     0    15           13   \n",
       "3  023ec7b5-cb8f-49a5-995f-e0d7c2f702e5           1     6    13           65   \n",
       "4  02efdb70-8596-4f3f-b0b2-b91e194f61f7           1     2     6           13   \n",
       "\n",
       "   platform_os  user_response  \n",
       "0            1              1  \n",
       "1            1              1  \n",
       "2            1              1  \n",
       "3            1              1  \n",
       "4            1              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Platform_copied = df_split.copy()\n",
    "df_platform = df_Platform_copied.drop(columns='browser', axis=1)\n",
    "df_platform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platform.to_csv('../data/data_with_platform.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>browser</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008aafdf-deef-4482-8fec-d98e3da054da</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00b6fadb-10bd-49e3-a778-290da82f7a8d</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018af862-486e-4da1-a85b-71872120e57c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023ec7b5-cb8f-49a5-995f-e0d7c2f702e5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02efdb70-8596-4f3f-b0b2-b91e194f61f7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id  experiment  date  hour  device_make  \\\n",
       "0  008aafdf-deef-4482-8fec-d98e3da054da           1     1    16           13   \n",
       "1  00b6fadb-10bd-49e3-a778-290da82f7a8d           0     5     4           43   \n",
       "2  018af862-486e-4da1-a85b-71872120e57c           0     0    15           13   \n",
       "3  023ec7b5-cb8f-49a5-995f-e0d7c2f702e5           1     6    13           65   \n",
       "4  02efdb70-8596-4f3f-b0b2-b91e194f61f7           1     2     6           13   \n",
       "\n",
       "   browser  user_response  \n",
       "0        1              1  \n",
       "1        4              1  \n",
       "2        1              1  \n",
       "3        4              1  \n",
       "4        1              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_os_copied = df_split.copy()\n",
    "df_os = df_os_copied.drop(columns='platform_os', axis=1)\n",
    "df_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os.to_csv('../data/data_with_os.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Data From DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dvc.api\n",
    "\n",
    "with dvc.api.open(\n",
    "    'data/data_with_os.csv',\n",
    "    mode='rb',\n",
    "    \n",
    ") as data:\n",
    "    df_with_browser = pd.read_csv(data)\n",
    "    df_with_browser.head()\n",
    "df_with_browser.drop(['auction_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Platform Os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>browser</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment  date  hour  device_make  browser  user_response\n",
       "0           1     1    16           13        1              1\n",
       "1           0     5     4           43        4              1\n",
       "2           0     0    15           13        1              1\n",
       "3           1     6    13           65        4              1\n",
       "4           1     2     6           13        1              1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_browser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1243, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_browser.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870, 5)\n",
      "(870,)\n",
      "(248, 5)\n",
      "(248,)\n",
      "(125, 5)\n",
      "(125,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df_with_browser, target = 'user_response', \n",
    "                                                                            train_size=0.7, valid_size=0.2, test_size=0.1)\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48850575 0.52873563 0.52873563 0.55172414 0.56321839]\n",
      "Mean Logistic Regression score for browser data : 0.5321839080459769\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "# scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model_predictions = model.predict(X_test)\n",
    "result=cross_val_score(estimator=model,X=X_train,y=y_train,cv=5,scoring='accuracy')\n",
    "\n",
    "print(result)\n",
    "print('Mean Logistic Regression score for browser data :',result.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.5321839080459769----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {result.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dvc.api.open(\n",
    "    'data/data_with_platform.csv',\n",
    "    mode='rb',\n",
    "    \n",
    ") as data:\n",
    "    df_with_platform_os = pd.read_csv(data)\n",
    "    df_with_platform_os.head()\n",
    "df_with_platform_os.drop(['auction_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment  date  hour  device_make  platform_os  user_response\n",
       "0           1     1    16           13            1              1\n",
       "1           0     5     4           43            1              1\n",
       "2           0     0    15           13            1              1\n",
       "3           1     6    13           65            1              1\n",
       "4           1     2     6           13            1              1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_platform_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870, 5)\n",
      "(870,)\n",
      "(248, 5)\n",
      "(248,)\n",
      "(125, 5)\n",
      "(125,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, y_train2, X_valid2, y_valid2, X_test2, y_test2 = train_valid_test_split(df_with_platform_os, target = 'user_response', \n",
    "                                                                            train_size=0.7,valid_size=0.2, test_size=0.1)\n",
    "\n",
    "\n",
    "print(X_train2.shape), print(y_train2.shape)\n",
    "print(X_valid2.shape), print(y_valid2.shape)\n",
    "print(X_test2.shape), print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2 = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52873563 0.55172414 0.59195402 0.54597701 0.56321839]\n",
      "Mean Logistic Regression score for Browser data : 0.5563218390804597\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "# scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train2, y_train2)\n",
    "model_predictions2 = model2.predict(X_test2)\n",
    "\n",
    "result2=cross_val_score(estimator=model2,X=X_train2,y=y_train2,cv=5,scoring='accuracy')\n",
    "\n",
    "print(result2)\n",
    "print('Mean Logistic Regression score for Browser data :',result2.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.5563218390804597----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {result2.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Platform Os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.54022989 0.53448276 0.51724138 0.51149425]\n",
      "Mean Logistic Regression score for platform os data : 0.5206896551724138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "decision_tree_model = clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "print('Mean Logistic Regression score for platform os data :',scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.5206896551724138----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {scores.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51149425 0.55172414 0.54022989 0.58045977 0.52873563]\n",
      "Mean Logistic Regression score for platform os data : 0.5425287356321838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "decision_tree_model = clf2.fit(X_train2, y_train2)\n",
    "clf_predictions2 = clf2.predict(X_test2)\n",
    "\n",
    "scores2 = cross_val_score(estimator=clf2, X=X_train2, y=y_train2, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores2)\n",
    "print('Mean Logistic Regression score for platform os data :',scores2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.5425287356321838----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {scores2.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Platform Os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>user_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment  date  hour  device_make  platform_os  user_response\n",
       "0           1     1    16           13            1              1\n",
       "1           0     5     4           43            1              1\n",
       "2           0     0    15           13            1              1\n",
       "3           1     6    13           65            1              1\n",
       "4           1     2     6           13            1              1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_platform_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:16:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.52298851 0.54022989 0.50574713 0.54597701 0.56321839]\n",
      "Mean Logistic Regression score for platform os data : 0.535632183908046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgbs = XGBClassifier(n_estimators=1000, learning_rate=0.1)\n",
    "\n",
    "xgbs.fit(\n",
    "    X_train, y_train,\n",
    "    early_stopping_rounds=5,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    " )\n",
    "xgbs_predictions = xgbs.predict(X_test)\n",
    "\n",
    "\n",
    "scores_xgb = cross_val_score(estimator=xgbs, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores_xgb)\n",
    "print('Mean Logistic Regression score for platform os data :',scores_xgb.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.535632183908046----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {scores_xgb.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Version With Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.48275862 0.54022989 0.51724138 0.51724138 0.53448276]\n",
      "Mean Logistic Regression score for platform os data : 0.5183908045977011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgbs2 = XGBClassifier(n_estimators=1000, learning_rate=0.1)\n",
    "\n",
    "xgbs2.fit(\n",
    "    X_train2, y_train2,\n",
    "    early_stopping_rounds=5,\n",
    "    eval_set=[(X_test2, y_test2)],\n",
    "    verbose=False\n",
    " )\n",
    "xgbs_predictions2 = xgbs2.predict(X_test2)\n",
    "\n",
    "\n",
    "scores_xgb2 = cross_val_score(estimator=xgbs2, X=X_train2, y=y_train2, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores_xgb2)\n",
    "print('Mean Logistic Regression score for platform os data :',scores_xgb2.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Accuracy: 0.5183908045977011----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----Accuracy: {scores_xgb2.mean()}----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Browser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47701149 0.5        0.50574713 0.53448276 0.55747126]\n",
      "Mean Logistic Regression score for platform os data : 0.5149425287356322\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators = 100)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_rf_predictions = clf_rf.predict(X_test)\n",
    "\n",
    "result_rf=cross_val_score(estimator=clf_rf,X=X_train,y=y_train,cv=5,scoring='accuracy')\n",
    "\n",
    "\n",
    "print(result_rf)\n",
    "print('Mean Logistic Regression score for platform os data :',result_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: 0.708046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Platform Os Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2 = RandomForestClassifier(n_estimators = 100)\n",
    "clf_rf2.fit(X_train2, y_train2)\n",
    "\n",
    "clf_rf2_predictions2 = clf_rf2.predict(X_test2)\n",
    "\n",
    "result_rf2=cross_val_score(estimator=clf_rf2,X=X_train2,y=y_train2,cv=5,scoring='accuracy')\n",
    "\n",
    "\n",
    "print(result_rf2)\n",
    "print('Mean Logistic Regression score for platform os data :',result_rf2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: 0.998851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Browser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_imp_feature = pd.DataFrame({\"Feature Importance\": model.coef_[0]})\n",
    "logistic_imp_feature[\"Feature\"] = ['experiment'\t,'date'\t,'hour','device_make',\t'browser']\n",
    "logistic_imp_feature = logistic_imp_feature.set_index(\"Feature\")\n",
    "logistic_imp_feature = logistic_imp_feature.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "logistic_imp_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Platform Os Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_imp_feature_os = pd.DataFrame({\"Feature Importance\": model2.coef_[0]})\n",
    "logistic_imp_feature_os[\"Feature\"] = ['experiment'\t,'date'\t,'hour','device_make',\t'platform_os']\n",
    "logistic_imp_feature_os = logistic_imp_feature_os.set_index(\"Feature\")\n",
    "logistic_imp_feature_os = logistic_imp_feature_os.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "logistic_imp_feature_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: platform_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Browser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_imp_feature_browser = pd.DataFrame({\"Feature Importance\": clf.feature_importances_})\n",
    "decision_imp_feature_browser[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"browser\"]\n",
    "decision_imp_feature_browser = decision_imp_feature_browser.set_index(\"Feature\")\n",
    "decision_imp_feature_browser = decision_imp_feature_browser.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "decision_imp_feature_browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Platform Os Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_imp_feature_platform = pd.DataFrame({\"Feature Importance\": clf2.feature_importances_})\n",
    "decision_imp_feature_platform[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"platform_os\"]\n",
    "decision_imp_feature_platform = decision_imp_feature_platform.set_index(\"Feature\")\n",
    "decision_imp_feature_platform = decision_imp_feature_platform.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "decision_imp_feature_platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Browser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbs2.feature_importances_\n",
    "xgb_imp_feature_browser = pd.DataFrame({\"Feature Importance\": xgbs2.feature_importances_})\n",
    "xgb_imp_feature_browser[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"browser\"]\n",
    "xgb_imp_feature_browser = xgb_imp_feature_browser.set_index(\"Feature\")\n",
    "xgb_imp_feature_browser = xgb_imp_feature_browser.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "xgb_imp_feature_browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: device_make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Platform Os Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbs2.feature_importances_\n",
    "xgb_imp_feature_platform = pd.DataFrame({\"Feature Importance\": xgbs2.feature_importances_})\n",
    "xgb_imp_feature_platform[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"platform_os\"]\n",
    "xgb_imp_feature_platform = xgb_imp_feature_platform.set_index(\"Feature\")\n",
    "xgb_imp_feature_platform = xgb_imp_feature_platform.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "xgb_imp_feature_platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: device_make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Browser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_imp_feature_browser = pd.DataFrame({\"Feature Importance\": clf_rf.feature_importances_})\n",
    "rand_imp_feature_browser[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"browser\"]\n",
    "rand_imp_feature_browser = rand_imp_feature_browser.set_index(\"Feature\")\n",
    "rand_imp_feature_browser = rand_imp_feature_browser.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "rand_imp_feature_browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Platform Os Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_imp_feature_platform = pd.DataFrame({\"Feature Importance\": clf_rf.feature_importances_})\n",
    "rand_imp_feature_platform[\"Feature\"] = [\"experiment\", \"date\", \"hour\", \"device_make\", \"platform_od\"]\n",
    "rand_imp_feature_platform = rand_imp_feature_platform.set_index(\"Feature\")\n",
    "rand_imp_feature_platform = rand_imp_feature_platform.sort_values(by=[\"Feature Importance\"], ascending=False)\n",
    "rand_imp_feature_platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Feature: hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the relevant features contributes to the goal of gaining more “Yes” results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************************************************************************************************************\n",
    "### For the above eight different models, the relevant features are \"hour\", \"platform_os\", \"device_make\". Therefore, these features contribute to the goal of geting more \"YES\" by targeting those features in playing ads.\n",
    "\n",
    "### For instance, doing the following might be a good measure after seeing these outputs \n",
    "     1. Exposing users the ads during the time most users respond \"YES\" to the ads.\n",
    "     2. Exposing users the ads on the devices most users respond \"YES\" to the ads. Or crafting strategies for users with device having  many \"NO\" responses.\n",
    "\n",
    "\n",
    "****************************************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which data features are relevant to predicting the target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"***********************\")\n",
    "print(\"Prediction Accuracy\")\n",
    "print(\"***********************\")\n",
    "\n",
    "# Logistic Regression\n",
    "accuracy_logistic = accuracy_score(y_test, model_predictions)\n",
    "accuracy_logistic2 = accuracy_score(y_test, model_predictions2) # for platform os data\n",
    "# Desicion Tree\n",
    "accuracy_decision = accuracy_score(y_test, clf_predictions)\n",
    "accuracy_decision2 = accuracy_score(y_test, clf_predictions2) # for platform os data\n",
    "# XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, xgbs_predictions)\n",
    "accuracy_xgb2 = accuracy_score(y_test, xgbs_predictions2) # for platform os data\n",
    "# Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, clf_rf_predictions)\n",
    "accuracy_rf2 = accuracy_score(y_test, clf_rf2_predictions2) # for platform os data\n",
    "\n",
    "print(\"Accuracy for Logistic Regression For Browser Data:\", accuracy_logistic)\n",
    "print(\"Accuracy for Logistic Regression:\", accuracy_logistic2)\n",
    "print(' ')\n",
    "print(\"Accuracy for Desicion Tree For Browser Data:\", accuracy_decision)\n",
    "print(\"Accuracy for Desicion Tree:\", accuracy_decision2)\n",
    "print(' ')\n",
    "\n",
    "print(\"Accuracy for XGBoost For Browser Data:\", accuracy_xgb)\n",
    "print(\"Accuracy for XGBoost:\", accuracy_xgb2)\n",
    "print(' ')\n",
    "\n",
    "print(\"Accuracy for Random Forest For Browser Data:\", accuracy_rf)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_rf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac73dea083c4a9bcc93446c53f809c1f9873c7c5b7a8513f70b72082cbeb4b4e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
